Given a dataset generated from a distribution with \ac{pdf} $f\in\HC{D}$, of primary interest is the estimation of $f$ and performing inference on the population's parameters. In general, estimation of $f \in \HC{D}$ involves estimation of $\mub$, $D$ and $f_0$. For a dataset $\xb_1, \dots, \xb_n$, an intuitive estimation approach might be to estimate the shape set and its gauge function, $\fncDtest[\est{D}]{n}{\xb - \mub}$, producing estimates of the star-generalized radius variables $\est{r}_1, \dots, \est{r}_n$ which can then be used to estimate the density generator. This process may be repeated using the estimate of the density generator to update the estimate of the shape set and so on until convergence. We call this general strategy the "iterative approach" as it is similar to the EM-Algorithm \citep{Dempster1977}, but such a strategy does not appear in the literature.

The framework for shape set estimation presented in \citet{Ferreira2005} uses free-knot splines with reversible-jump Markov chain Monte Carlo to produce samples from the posterior distribution of $D$. While this leads directly to inference, it can be computationally intensive, require many inputs from the user such as prior distributions and tuning parameters, and assumes knowledge of the density generator. 

Parametric estimators for the shape set are presented in \citet{Liebscher2016} along with both parametric and non-parametric estimators for $f_0$. By combining estimators of $D$ and $f_0$, both fully and semiparametric estimators for the entire density are derived. This approach is constrained by requiring $D$ to have a parametric form symmetric about the origin with $\Exp{R^2} < \nf$.

The nonparametric shape set estimator of \citet{Kamiya2019} applies a transformation to the kernel density estimator of direction and is very promising in that it is strongly consistent with respect to the Hausdorff distance and is not affected by the density generator. This latter fact implies that one can estimate the shape set first, though inference is affected by the number of observations, the kernel bandwidth selection, and dimensionality. The authors do not discuss the use of this estimator or its performance as part of the larger density estimation problem.

Flexible parametric families with few, interpretable parameters are desireable for density estimation and inference as they allow for estimation via maximum likelihood. Under regularity conditions \citep[Section 6.1]{Hogg2005}, the maximum likelihood estimators are asymptotically normally distributed and inference follows directly from the observed information matrix and deviance function. This motivates the search for such parametric families. Fully parametric model classes are introduced in \citet{Liebscher2020} enabling the maximum likelihood approach to estimating $f \in \HC{D}$, but are separate classes of distributions.

We introduce a fully parametric subclass of star-shaped distributions on $\R^2$ with densities $f \in \HC{D}$ called the trochoidal distributions, characterized by having density level sets whose boundaries can be traced by centered trochoids. This class is the union of the epitrochoidal and hypotrochoidal distribution families also introduced here. In the bivariate setting, this class offers flexible distributions with only a few parameters whose interpretations are direct and practical. In addition, the trochoidal distributions are a generalization of the elliptical class since an ellipse is a trochoid \citep{Pedoe1975}. This generalization is geometric in the sense that the shape of the density contours can be traced by any centered trochoid under certain constraints on the trochoidal parameters that lead to identifiable distributions with densities $f \in \HC{D}$. The trochoidal distributions can be estimated via maximum likelihood and inference follows as in \citet{Liebscher2020}. The parameters have straightforward interpretations regarding the degree, direction, and number of directions of dependence.