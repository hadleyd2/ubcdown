By a simple rearrangement of the terms in Equation \eqref{Eq:stargen}, the radial variable is a function of the star-generalized radius variable and the polar function for $\bdry{D}$, \eqq{
  \Rho = R\cdot \fncD{r}{\Tbm}.
} Taking the expectation of both sides given $\Tbm = \tbm$, \eeq[condition-mean]{
  \Exp{\Rho \mmid \Tbm = \tbm} = \Exp{R\mmid \Tbm=\tbm}\fncD{r}{\tbm} = \Exp{R}\fncD{r}{\tbm} = \ka\fncD{r}{\tbm}, \qquad \tbm \in \O, \ \ka = \Exp{R},
} where we write $\Exp{R}$ as a constant $\ka > 0$ using the independence of $R$ and \mbox{$\Tbm$ \citep[Thm 3.1]{Kamiya2008}}. As discussed in Section \@ref(estimation), the constant of proportionality is accounted for through a scaling parameter in the density generator. We can thus treat estimation of $\fncD{r}{\cdot}$ as estimation of the conditional expectation of the radial variable.

Estimation of a conditional expectation is well studied with many approaches. We look at nonparametric kernel regression and smoothing spline estimators and a semiparametric approach using free-knot splines to estimate the conditional expectation.

The nonparametric model for the conditional expectation of the radial variable is \eeq[cond-mean]{
  \fnc{m}{\tbm} = \ka\fncD{r}{\tbm},
} where Equation \eqref{Eq:cond-mean} is well-defined when \eqq{
  \Exp{R} = \int_{0}^{\nf}p\abs{D}r^p\fnc{f_0}{r}dr < \nf.
}

Two common nonparametric estimators, Nadaraya-Watson \citep{Nadaraya1964, Watson1964} and periodic smoothing splines, were used to estimate the conditional expectation in the bivariate setting due to their simplicity. However, the discussion of these estimators and their preliminary results are excluded from this proposal to preserve space, since neither method easily generalizes to higher dimensions. 

<!-- The model for the conditional expectation of the radial variable for the nonparametric approaches is \eeq[cond-mean]{ -->
<!--   \fnc{m}{\tbm} = \ka\fncD{r}{\tbm}, -->
<!-- } where Equation \eqref{Eq:cond-mean} is well-defined when $\Exp{R}$ exists ($\ka < \nf$). Using the \ac{pdf} for the star-generalized radius variable in Equation \eqref{Eq:scale-r}, the condition under which the regression problem is well-defined is \eqq{ -->
<!--   \int_{0}^{\nf}p\abs{D}r^p\fnc{f_0}{r}dr < \nf. -->
<!-- } -->

<!-- As an example where the model in Equation \eqref{Eq:cond-mean} is not well-defined, suppose our data is generated from a bivariate $t$-distribution with $1$ degree of freedom (a bivariate Cauchy distribution). The density generator is of the form \eqq{ -->
<!--   \fnc{f_0}{r} \propto \ \dfrac{1}{\paren{1 + r^2}^{3/2}}. -->
<!-- } Then, the expected value of the star-generalized radius variable is \eqq{ -->
<!--   \Exp{R} \ \propto \ \int_{0}^{\nf}\dfrac{r^2}{\paren{1 + r^2}^{3/2}}dr = \nf. -->
<!-- } Since this integral does not converge, the regression problem is not well-defined and estimators of $\fnc{m}{\tbm}$ can be misleading. -->

<!-- When modelling real data where we do not know the true density generator, one has to make an assumption that $\Exp{R} < \nf$. A simple diagnostic for assessing the appropriateness of this assumption is as follows: suppose we have a dataset, $\XC_n = \xb_1, \dots, \xb_n$, of independent and identically distributed random variables generated from density $f \in \HC{D}$. Let $\XC_i = \xb_1, \dots, \xb_i$ for $i = 1, \dots, n$ be a subset of the data. Then, estimate $\fnc{m}{\tbm}$ for datasets $\XC_{i_1}, \XC_{i_2}, \dots, \XC_{n}$ where $\XC_{i_1} \ss \XC_{i_2} \ss \cdots \ss \XC_{n}$. When $\Exp{R}$ is not finite, the estimated shape set is likely to get larger with the size of the dataset. -->